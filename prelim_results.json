[{"kind": "customsearch#result", "title": "AI alignment - Wikipedia", "htmlTitle": "<b>AI alignment</b> - Wikipedia", "link": "https://en.wikipedia.org/wiki/AI_alignment", "displayLink": "en.wikipedia.org", "snippet": "In the field of artificial intelligence (AI), AI alignment research aims to steer AI systems towards humans' intended goals, preferences,\u00a0...", "htmlSnippet": "In the field of artificial intelligence (AI), <b>AI alignment</b> research aims to steer AI systems towards humans&#39; intended goals, preferences,&nbsp;...", "cacheId": "OncmE5HBayQJ", "formattedUrl": "https://en.wikipedia.org/wiki/AI_alignment", "htmlFormattedUrl": "https://en.wikipedia.org/wiki/<b>AI</b>_<b>alignment</b>", "pagemap": {"metatags": [{"referrer": "origin", "og:image": "https://upload.wikimedia.org/wikipedia/commons/1/1c/Artificial_intelligence_prompt_completion_by_dalle_mini.jpg", "theme-color": "#eaecf0", "og:image:width": "1200", "og:type": "website", "viewport": "width=device-width, initial-scale=1.0, user-scalable=yes, minimum-scale=0.25, maximum-scale=5.0", "og:title": "AI alignment - Wikipedia", "og:image:height": "1200", "format-detection": "telephone=no"}]}}, {"kind": "customsearch#result", "title": "Our approach to alignment research", "htmlTitle": "Our approach to <b>alignment</b> research", "link": "https://openai.com/blog/our-approach-to-alignment-research", "displayLink": "openai.com", "snippet": "Aug 24, 2022 ... We are improving our AI systems' ability to learn from human feedback and to assist humans at evaluating AI. Our goal is to build a\u00a0...", "htmlSnippet": "Aug 24, 2022 <b>...</b> We are improving our <b>AI</b> systems&#39; ability to learn from human feedback and to assist humans at evaluating <b>AI</b>. Our goal is to build a&nbsp;...", "cacheId": "K_HzbrrsCh8J", "formattedUrl": "https://openai.com/blog/our-approach-to-alignment-research", "htmlFormattedUrl": "https://openai.com/blog/our-approach-to-<b>alignment</b>-research", "pagemap": {"metatags": [{"og:image": "https://images.openai.com/blob/74b55508-ca20-4414-8fda-b45379d6b3f8/our-approach-to-alignment-research.png", "og:image:alt": "Our Approach To Alignment Research", "twitter:card": "summary_large_image", "twitter:site": "@OpenAI", "viewport": "width=device-width, initial-scale=1", "og:title": "Our approach to alignment research", "og:description": "We are improving our AI systems\u2019 ability to learn from human feedback and to assist humans at evaluating AI. Our goal is to build a sufficiently aligned AI system that can help us solve all other alignment\u00a0problems.", "twitter:image": "https://images.openai.com/blob/74b55508-ca20-4414-8fda-b45379d6b3f8/our-approach-to-alignment-research.png"}], "cse_image": [{"src": "https://images.openai.com/blob/74b55508-ca20-4414-8fda-b45379d6b3f8/our-approach-to-alignment-research.png"}]}}, {"kind": "customsearch#result", "title": "AI Alignment Forum", "htmlTitle": "<b>AI Alignment</b> Forum", "link": "https://www.alignmentforum.org/", "displayLink": "www.alignmentforum.org", "snippet": "A community blog devoted to technical AI alignment research.", "htmlSnippet": "A community blog devoted to technical <b>AI alignment</b> research.", "cacheId": "pk0DEDqV9q8J", "formattedUrl": "https://www.alignmentforum.org/", "htmlFormattedUrl": "https://www.<b>alignment</b>forum.org/", "pagemap": {"cse_thumbnail": [{"src": "https://encrypted-tbn1.gstatic.com/images?q=tbn:ANd9GcTqT0OZ_inx3_Oo3-tAdx-SKcnaYL1gblZSZtMQrBFcDeGMRqGVvRle8bEz", "width": "345", "height": "146"}], "metatags": [{"og:image": "https://res.cloudinary.com/lesswrong-2-0/image/upload/v1654295382/new_mississippi_river_fjdmww.jpg", "twitter:card": "summary_large_image", "og:type": "article", "viewport": "width=device-width, initial-scale=1", "twitter:description": "A community blog devoted to technical AI alignment research", "og:url": "https://www.alignmentforum.org/", "og:description": "A community blog devoted to technical AI alignment research", "twitter:image:src": "https://res.cloudinary.com/lesswrong-2-0/image/upload/v1654295382/new_mississippi_river_fjdmww.jpg"}], "cse_image": [{"src": "https://res.cloudinary.com/lesswrong-2-0/image/upload/v1654295382/new_mississippi_river_fjdmww.jpg"}]}}, {"kind": "customsearch#result", "title": "AI Alignment", "htmlTitle": "<b>AI Alignment</b>", "link": "https://ai-alignment.com/", "displayLink": "ai-alignment.com", "snippet": "AI Alignment \u00b7 Decoupling deliberation from competition. A possible framing of intent alignment. \u00b7 Mundane solutions to exotic problems. I often think about\u00a0...", "htmlSnippet": "<b>AI Alignment</b> &middot; Decoupling deliberation from competition. A possible framing of intent alignment. &middot; Mundane solutions to exotic problems. I often think about&nbsp;...", "cacheId": "8fLMC2sSD3YJ", "formattedUrl": "https://ai-alignment.com/", "htmlFormattedUrl": "https://<b>ai</b>-<b>alignment</b>.com/", "pagemap": {"cse_thumbnail": [{"src": "https://encrypted-tbn3.gstatic.com/images?q=tbn:ANd9GcQWebFlIWZwTt8rGddb5MoG9sYPnVhKWpNobOspilGbcWlQzT0BOW0MUFQ", "width": "225", "height": "225"}], "metatags": [{"og:image": "https://cdn-images-1.medium.com/max/1200/1*N56Qc5-aHTcfGff0scntKQ.png", "twitter:app:url:iphone": "medium://ai-control", "theme-color": "#000000", "twitter:card": "summary_large_image", "og:site_name": "AI Alignment", "al:android:package": "com.medium.reader", "title": "AI Alignment", "twitter:app:id:iphone": "828256236", "al:ios:url": "medium://ai-control", "og:description": "Aligning AI systems with human interests.", "al:ios:app_store_id": "828256236", "twitter:site": "@Medium", "medium-com:creator": "https://ai-alignment.com/@paulfchristiano", "twitter:title": "AI Alignment", "og:type": "website", "al:ios:app_name": "Medium", "og:title": "AI Alignment", "al:web:url": "https://ai-alignment.com/", "twitter:image:src": "https://cdn-images-1.medium.com/max/1200/1*N56Qc5-aHTcfGff0scntKQ.png", "al:android:url": "medium://ai-control", "referrer": "always", "fb:app_id": "542599432471018", "viewport": "width=device-width, initial-scale=1.0, viewport-fit=contain", "twitter:description": "Aligning AI systems with human interests.", "og:url": "https://ai-alignment.com/", "twitter:app:name:iphone": "Medium", "al:android:app_name": "Medium"}], "cse_image": [{"src": "https://cdn-images-1.medium.com/max/1200/1*N56Qc5-aHTcfGff0scntKQ.png"}]}}, {"kind": "customsearch#result", "title": "What is the AI alignment problem and how can it be solved? | New ...", "htmlTitle": "What is the <b>AI alignment</b> problem and how can it be solved? | New ...", "link": "https://www.newscientist.com/article/mg25834382-000-what-is-the-ai-alignment-problem-and-how-can-it-be-solved/", "displayLink": "www.newscientist.com", "snippet": "May 10, 2023 ... Artificial intelligence systems will do what you ask but not necessarily ... In any case, the challenges of AI alignment are significant,\u00a0...", "htmlSnippet": "May 10, 2023 <b>...</b> Artificial intelligence systems will do what you ask but not necessarily ... In any case, the challenges of <b>AI alignment</b> are significant,&nbsp;...", "cacheId": "H8uE2Kq2k7AJ", "formattedUrl": "https://www.newscientist.com/.../mg25834382-000-what-is-the-ai-alignment- problem-and-how-can-it-be-solved/", "htmlFormattedUrl": "https://www.newscientist.com/.../mg25834382-000-what-is-the-<b>ai</b>-<b>alignment</b>- problem-and-how-can-it-be-solved/", "pagemap": {"cse_thumbnail": [{"src": "https://encrypted-tbn2.gstatic.com/images?q=tbn:ANd9GcRqVS6M0mvslqRwEHjRP7Im_6cETZezct0_zf3l7uTyc6tz9P11US1VhiOw", "width": "275", "height": "183"}], "thumbnail": [{"src": "https://images.newscientist.com/wp-content/uploads/2023/05/09122707/SEI_154688016.jpg"}], "metatags": [{"p:domain_verify": "e1ad6b074bd56738db29f7d0150698c9", "apple-itunes-app": "app-id=671845403", "og:image": "https://images.newscientist.com/wp-content/uploads/2023/05/09122707/SEI_154688016.jpg", "thumbnail": "https://images.newscientist.com/wp-content/uploads/2023/05/09122707/SEI_154688016.jpg", "og:type": "article", "twitter:card": "summary_large_image", "twitter:title": "What is the AI alignment problem and how can it be solved?", "og:site_name": "New Scientist", "author": "#author.fullName}", "og:title": "What is the AI alignment problem and how can it be solved?", "og:description": "Artificial intelligence systems will do what you ask but not necessarily what you meant. The challenge is to make sure they act in line with human\u2019s complex, nuanced values", "twitter:creator": "@newscientist", "twitter:image": "https://images.newscientist.com/wp-content/uploads/2023/05/09122707/SEI_154688016.jpg", "twitter:site": "@newscientist", "viewport": "width=device-width, initial-scale=1.0, maximum-scale=1.5", "news_keywords": "artificial intelligence,algorithms,technology,Computers", "twitter:description": "Artificial intelligence systems will do what you ask but not necessarily what you meant. The challenge is to make sure they act in line with human\u2019s complex, nuanced values", "onesignal": "wordpress-plugin", "og:locale": "en_US", "og:url": "https://www.newscientist.com/article/mg25834382-000-what-is-the-ai-alignment-problem-and-how-can-it-be-solved/", "ob_page_type": "non-paywall"}], "cse_image": [{"src": "https://images.newscientist.com/wp-content/uploads/2023/05/09122707/SEI_154688016.jpg"}]}}, {"kind": "customsearch#result", "title": "AI Alignment: Why It's Hard, and Where to Start - Machine ...", "htmlTitle": "<b>AI Alignment</b>: Why It&#39;s Hard, and Where to Start - Machine ...", "link": "https://intelligence.org/2016/12/28/ai-alignment-why-its-hard-and-where-to-start/", "displayLink": "intelligence.org", "snippet": "Dec 28, 2016 ... AI alignment: treat it like a cryptographic rocket probe. This is about how difficult you would expect it to be to build something smarter than\u00a0...", "htmlSnippet": "Dec 28, 2016 <b>...</b> <b>AI alignment</b>: treat it like a cryptographic rocket probe. This is about how difficult you would expect it to be to build something smarter than&nbsp;...", "cacheId": "hTMVFH6KZ9MJ", "formattedUrl": "https://intelligence.org/2016/.../ai-alignment-why-its-hard-and-where-to-start/", "htmlFormattedUrl": "https://intelligence.org/2016/.../<b>ai</b>-<b>alignment</b>-why-its-hard-and-where-to-start/", "pagemap": {"cse_thumbnail": [{"src": "https://encrypted-tbn3.gstatic.com/images?q=tbn:ANd9GcRl9Dh2K6P2mZ-vwoFThiJiJER63aeBokAdeOfm9agRgxXlG_AQJRSc3-A", "width": "259", "height": "194"}], "metatags": [{"og:image": "https://intelligence.org/wp-content/uploads/2016/12/ai-alignment-problem-presentationhq1-2.png", "og:type": "article", "article:published_time": "2016-12-28T21:51:47+00:00", "twitter:card": "summary_large_image", "og:site_name": "Machine Intelligence Research Institute", "author": "Eliezer Yudkowsky", "og:title": "AI Alignment: Why It's Hard, and Where to Start - Machine Intelligence Research Institute", "twitter:label1": "Written by", "twitter:label2": "Est. reading time", "og:description": "Back in May, I gave a talk at Stanford University for the Symbolic Systems Distinguished Speaker series, titled \u201cThe AI Alignment Problem: Why It\u2019s Hard, And Where To Start.\u201d The video for this talk is now available on Youtube: \u00a0 \u00a0 We have an approximately complete transcript of the talk and Q&A session here, slides... Read more \u00bb", "twitter:creator": "@MIRIBerkeley", "article:publisher": "https://www.facebook.com/MachineIntelligenceResearchInstitute", "twitter:image": "https://intelligence.org/wp-content/uploads/2017/06/fblink.jpg", "twitter:data1": "Eliezer Yudkowsky", "twitter:data2": "48 minutes", "twitter:site": "@MIRIBerkeley", "article:modified_time": "2017-12-07T03:05:09+00:00", "viewport": "width=device-width", "og:locale": "en_US", "og:url": "https://intelligence.org/2016/12/28/ai-alignment-why-its-hard-and-where-to-start/"}], "cse_image": [{"src": "https://intelligence.org/wp-content/uploads/2016/12/ai-alignment-problem-presentationhq1-2.png"}], "blogposting": [{"articlebody": "Back in May, I gave a talk at Stanford University for the Symbolic Systems Distinguished Speaker series, titled \u201cThe AI Alignment Problem: Why It\u2019s Hard, And Where To Start.\u201d The video...", "headline": "AI Alignment: Why It\u2019s Hard, and Where to Start"}]}}, {"kind": "customsearch#result", "title": "What is AI alignment? | Definition from TechTarget", "htmlTitle": "What is <b>AI alignment</b>? | Definition from TechTarget", "link": "https://www.techtarget.com/whatis/definition/AI-alignment", "displayLink": "www.techtarget.com", "snippet": "AI alignment is a field of AI safety research that aims to ensure artificial intelligence systems achieve desired outcomes. AI alignment research keeps AI\u00a0...", "htmlSnippet": "<b>AI alignment</b> is a field of AI safety research that aims to ensure artificial intelligence systems achieve desired outcomes. <b>AI alignment</b> research keeps AI&nbsp;...", "formattedUrl": "https://www.techtarget.com/whatis/definition/AI-alignment", "htmlFormattedUrl": "https://www.techtarget.com/whatis/definition/<b>AI</b>-<b>alignment</b>", "pagemap": {"cse_thumbnail": [{"src": "https://encrypted-tbn1.gstatic.com/images?q=tbn:ANd9GcQFaWySxbI0tz9CPdmU3_sZEQ-nmP2f-_ACHM6MxC3-kIaVhTEDECEdRt0", "width": "308", "height": "163"}], "metatags": [{"og:image": "https://cdn.ttgtmedia.com/ITKE/images/logos/TTlogo-379x201.png", "og:type": "article", "twitter:card": "summary_large_image", "twitter:title": "What is AI alignment? | Definition from TechTarget", "og:site_name": "WhatIs.com", "og:title": "What is AI alignment? | Definition from TechTarget", "og:description": "Alignment keeps AI working for humans. Learn the challenges of AI alignment and how different organizations approach it.", "article:publisher": "https://www.facebook.com/WhatIsDotCom/", "twitter:image": "https://cdn.ttgtmedia.com/ITKE/images/logos/TTlogo-379x201.png", "fb:app_id": "870327132989388", "twitter:site": "@WhatIsDotCom", "viewport": "width=device-width,initial-scale=1", "twitter:description": "Alignment keeps AI working for humans. Learn the challenges of AI alignment and how different organizations approach it.", "og:locale": "en_US", "og:url": "https://www.techtarget.com/whatis/definition/AI-alignment"}], "cse_image": [{"src": "https://cdn.ttgtmedia.com/ITKE/images/logos/TTlogo-379x201.png"}]}}, {"kind": "customsearch#result", "title": "Paul Christiano: Current Work in AI Alignment | Effective Altruism", "htmlTitle": "Paul Christiano: Current Work in <b>AI Alignment</b> | Effective Altruism", "link": "https://www.effectivealtruism.org/articles/paul-christiano-current-work-in-ai-alignment", "displayLink": "www.effectivealtruism.org", "snippet": "What I mean is \u201cintent alignment,\u201d which is trying to build AI systems that are trying to do what you want them to do. In some sense, this might be the minimum\u00a0...", "htmlSnippet": "What I mean is \u201cintent <b>alignment</b>,\u201d which is trying to build <b>AI</b> systems that are trying to do what you want them to do. In some sense, this might be the minimum&nbsp;...", "cacheId": "vtauPzmQ5aMJ", "formattedUrl": "https://www.effectivealtruism.org/.../paul-christiano-current-work-in-ai- alignment", "htmlFormattedUrl": "https://www.effectivealtruism.org/.../paul-christiano-current-work-in-<b>ai</b>- <b>alignment</b>", "pagemap": {"cse_thumbnail": [{"src": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcT-lqNRiQO_tmjVViZIMcT49wjNU4H2vldP_QVMnVPSPGu720Zr4N-1YWPF", "width": "225", "height": "225"}], "metatags": [{"og:image": "https://res.cloudinary.com/cea/image/upload/v1655223826/ea-logo-square.png", "next-head-count": "9", "viewport": "width=device-width"}], "cse_image": [{"src": "https://res.cloudinary.com/cea/image/upload/v1655223826/ea-logo-square.png"}]}}, {"kind": "customsearch#result", "title": "A Multilevel Framework for the AI Alignment Problem - Markkula ...", "htmlTitle": "A Multilevel Framework for the <b>AI Alignment</b> Problem - Markkula ...", "link": "https://www.scu.edu/ethics/focus-areas/technology-ethics/resources/a-multilevel-framework-for-the-ai-alignment-problem/", "displayLink": "www.scu.edu", "snippet": "This leads to the AI alignment problem: AI alignment is the issue of how we can encode AI systems in a way that is compatible with human moral values.", "htmlSnippet": "This leads to the <b>AI alignment</b> problem: <b>AI alignment</b> is the issue of how we can encode AI systems in a way that is compatible with human moral values.", "cacheId": "yyvrR1ah69UJ", "formattedUrl": "https://www.scu.edu/.../a-multilevel-framework-for-the-ai-alignment-problem /", "htmlFormattedUrl": "https://www.scu.edu/.../a-multilevel-framework-for-the-<b>ai</b>-<b>alignment</b>-problem /", "pagemap": {"cse_thumbnail": [{"src": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTt7vJDhrCi-fgjmbuYpk5_JPFM49l6wkxua-EdoeezAsXyBYmodqOsG_M", "width": "283", "height": "178"}], "metatags": [{"msapplication-tilecolor": "#da532c", "og:image": "https://www.scu.edu/media/ethics-center/technology-ethics/Hou_Multilevel-Framework-AI-Alignment-Image-356x225.png", "theme-color": "#ffffff", "og:type": "article", "twitter:card": "summary_large_image", "twitter:title": "A Multilevel Framework for the AI Alignment Problem", "author": "Santa Clara University", "og:title": "A Multilevel Framework for the AI Alignment Problem", "msapplication-tileimage": "/assets/images/favicons/mstile-144x144.png", "pageid": "102098", "og:description": "From social media algorithms, to smart home devices, to semi-autonomous vehicles, AI has found its way into nearly every aspect of our everyday lives.", "og:image:secure_url": "https://www.scu.edu/media/ethics-center/technology-ethics/Hou_Multilevel-Framework-AI-Alignment-Image-356x225.png", "twitter:image": "https://www.scu.edu/media/ethics-center/technology-ethics/Hou_Multilevel-Framework-AI-Alignment-Image-356x225.png", "twitter:site": "@SantaClaraUniv", "viewport": "width=device-width, initial-scale=1", "twitter:description": "From social media algorithms, to smart home devices, to semi-autonomous vehicles, AI has found its way into nearly every aspect of our everyday lives.", "og:url": "https://www.scu.edu/ethics/focus-areas/technology-ethics/resources/a-multilevel-framework-for-the-ai-alignment-problem/"}], "cse_image": [{"src": "https://www.scu.edu/media/ethics-center/technology-ethics/Hou_Multilevel-Framework-AI-Alignment-Image-356x225.png"}]}}, {"kind": "customsearch#result", "title": "MIT AI Alignment", "htmlTitle": "MIT <b>AI Alignment</b>", "link": "https://www.mitalignment.org/", "displayLink": "www.mitalignment.org", "snippet": "MIT AI Alignment. Home ... AI Safety Fundamentals \u00b7 GPS Fellowship. We're a student group conducting research to reduce risks from advanced AI.", "htmlSnippet": "MIT <b>AI Alignment</b>. Home ... AI Safety Fundamentals &middot; GPS Fellowship. We&#39;re a student group conducting research to reduce risks from advanced AI.", "cacheId": "9940LXvf16sJ", "formattedUrl": "https://www.mitalignment.org/", "htmlFormattedUrl": "https://www.mit<b>alignment</b>.org/", "pagemap": {"cse_thumbnail": [{"src": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRF3qakNKgigyylPwl97d5t6HbHZNZxVW-vtB2grd4pCsleO7VrG3TFId0", "width": "261", "height": "193"}], "metatags": [{"og:image": "http://static1.squarespace.com/static/630e5b312ba8ba2c58fe3bb4/t/6324c4f824ea9b17425c3b3f/1663354104189/307137783_633902914954025_3346080233651244476_n.png?format=1500w", "og:type": "website", "og:image:width": "744", "twitter:title": "MIT AI Alignment", "twitter:card": "summary", "og:site_name": "MIT AI Alignment", "viewport": "width=device-width, initial-scale=1", "twitter:url": "https://www.mitalignment.org", "og:title": "MIT AI Alignment", "og:image:height": "550", "og:url": "https://www.mitalignment.org", "twitter:image": "http://static1.squarespace.com/static/630e5b312ba8ba2c58fe3bb4/t/6324c4f824ea9b17425c3b3f/1663354104189/307137783_633902914954025_3346080233651244476_n.png?format=1500w"}], "cse_image": [{"src": "http://static1.squarespace.com/static/630e5b312ba8ba2c58fe3bb4/t/6324c4f824ea9b17425c3b3f/1663354104189/307137783_633902914954025_3346080233651244476_n.png?format=1500w"}]}}]